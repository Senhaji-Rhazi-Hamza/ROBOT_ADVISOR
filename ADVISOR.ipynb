{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the requests library\n",
    "import requests\n",
    "from cvxopt import matrix, solvers\n",
    "import json\n",
    "import datetime\n",
    "from dateutil.relativedelta import *\n",
    "from forex_python.converter import CurrencyRates\n",
    "import numpy as np\n",
    "import re\n",
    "solvers.options['show_progress'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "class RequestManadger:\n",
    "    def __init__(self, url,  user = '', password = '',auth = True, conex=True):\n",
    "        self.url = url\n",
    "        self.session = requests.Session()\n",
    "        self.load_datas()\n",
    "        self.rest = 0\n",
    "        if(conex):\n",
    "            if (auth):\n",
    "                if ((user != '') and (password != '')):\n",
    "                    self.user = user\n",
    "                    self.session.auth = (user, password)\n",
    "                    self.session.headers.update({'x-test': 'true'})\n",
    "                    r = self.session.get(self.url, verify = False)\n",
    "                #self.port_id= rm.get_request(\"asset?columns=ASSET_DATABASE_ID&columns=LABEL&columns=TYPE&TYPE=PORTFOLIO\")[0]['ASSET_DATABASE_ID']['value']\n",
    "                    self.port_id = 573\n",
    "                \n",
    "                \n",
    "                else :\n",
    "                    print(\"you should precise explicitly auth = false if \"\n",
    "                          \"you dont want add a user name and a password\")\n",
    "            else:\n",
    "                return self.session.get(self.url, verify = False)\n",
    "    def load_datas(self):\n",
    "        datas = {'ids':'my_ids.txt',\"ass\":\"my_assets.txt\",\n",
    "                 \"corr\":\"my_corr.txt\",'ass65':\"my_assets65.txt\",\n",
    "                 \"var\":\"my_vars.txt\",\"shp65\":\"my_sharpes65.txt\",\n",
    "                 \"cov\":\"my_cov.txt\",\"shp\":\"my_sharpes.txt\",\n",
    "                 \"prx_cur\":\"my_prx_curr.txt\"}\n",
    "        \n",
    "        self.ids = self.read_file(datas['ids']).astype(int)\n",
    "        self.assets = self.read_file(datas['ass'])\n",
    "        self.sharpes = self.read_file(datas['shp'])\n",
    "        self.assets65 = self.read_file(datas['ass65'])\n",
    "        self.sharpes65 = self.read_file(datas['shp65'])\n",
    "        self.prx_cur = self.read_file(datas['prx_cur'], prx_cur = True).T\n",
    "        self.vars = self.read_file(datas['var'])\n",
    "        self.corr =  self.read_file(datas['corr'])\n",
    "        self.cov =  self.read_file(datas['cov'])\n",
    "        self.cov2 = np.cov(self.assets65)\n",
    "        self.corr2 = np.array([[self.cov2[i][j]/np.sqrt(np.var(self.assets65[i]) * np.var(self.assets65[j])) for j in range(self.cov2.shape[0])] for i in range(self.cov2.shape[1])])\n",
    "      \n",
    "        \n",
    "    def get_request(self,req):\n",
    "        r = self.session.get(self.url + \"/\" + req, verify = False) \n",
    "        return json.loads(r.text)\n",
    "    def get_assetsids(self):\n",
    "        r = self.session.get(self.url + \"/asset\" , verify = False)\n",
    "        dic = json.loads(r.text)\n",
    "        N = len(dic)\n",
    "        ass_ids = np.zeros(N)\n",
    "        for i in range(N):\n",
    "            ass_ids[i] = int(dic[i][\"ASSET_DATABASE_ID\"][\"value\"])\n",
    "        self.ids = ass_ids.astype(int)\n",
    "        self.write_file(self.ids, \"my_ids.txt\")\n",
    "        return self.ids\n",
    "    def get_asset_vecrs(self, ids, jump = 1, allinone = False):\n",
    "        start = datetime.datetime(2012,1,1)\n",
    "        end = datetime.datetime(2017,6,1)\n",
    "        months = (end.year - start.year) * 12 + (end.month - start.month)\n",
    "        asset_vecr = []\n",
    "        asset_vecs =[]\n",
    "        \n",
    "        if not(allinone):\n",
    "            end =  start + relativedelta(months=+jump)\n",
    "        else:\n",
    "            months = 1\n",
    "\n",
    "        \n",
    "        for i in range(months):\n",
    "            obj2 = {'ratio':[21,20],'asset':[int(ids[i]) for i in range(len(ids))],'start_date':start.isoformat(),'end_date':end.isoformat(),'frequency':None}\n",
    "            obj = json.dumps(obj2)\n",
    "            r = self.session.post(self.url + \"/ratio/invoke\", data = obj, verify = False)\n",
    "            dic = json.loads(r.text)\n",
    "            asset_vecr.append([float((dic[str(ids[i])]['21']['value']).replace(\",\",'.')) for i in range(len(ids))])\n",
    "            asset_vecs.append([float((dic[str(ids[i])]['20']['value']).replace(\",\",'.')) for i in range(len(ids))])\n",
    "            \n",
    "            start = start + relativedelta(months=+jump)\n",
    "            end = end + relativedelta(months=+jump)\n",
    "        asset_vecr = np.array(asset_vecr)\n",
    "        asset_vecs = np.array(asset_vecs)\n",
    "        if not(allinone):\n",
    "            self.write_file(asset_vecr.T, 'my_assets65.txt')\n",
    "            self.write_file(asset_vecs.T, 'my_sharpes65.txt')\n",
    "        else:\n",
    "            self.write_file(asset_vecr, 'my_assets.txt')\n",
    "            self.write_file(asset_vecs, 'my_sharpes.txt')\n",
    "            \n",
    "        return asset_vecr, asset_vecs\n",
    "    def write_file(self, data, name):\n",
    "        f1 = open(name, \"w\")\n",
    "        if (len(data.shape) == 2):\n",
    "            for i in range(data.shape[0]):\n",
    "                for j in range(data.shape[1] - 1):\n",
    "                    f1.write(str(data[i][j]) + ' ')\n",
    "                f1.write(str(data[i,data.shape[1] - 1]) + '\\n')\n",
    "        else:\n",
    "            for i in range(data.shape[0] - 1):\n",
    "                    f1.write(str(data[i]) + ' ')\n",
    "            f1.write(str(data[data.shape[0] - 1]) + '\\n')\n",
    "        f1.close()\n",
    "    def read_file(self, name, prx_cur = False):\n",
    "        f1 = open(name, \"r\")\n",
    "        data = f1.readlines()\n",
    "\n",
    "        f1.close()\n",
    "        if (len(data) == 1):\n",
    "            return np.array(data[0].split()).astype(np.float32)\n",
    "        else:\n",
    "            if(prx_cur):\n",
    "                data= np.array([np.array(data[i].split()) for i in range(len(data))])\n",
    "                return np.array([data[:,0].astype(np.float64), data[:,1]])\n",
    "            else:\n",
    "                return np.array([np.array(data[i].split()).astype(np.float64) for i in range(len(data))])\n",
    "    \n",
    "    \n",
    "        \n",
    "    def corr_matrix(self):\n",
    "        ids = self.ids\n",
    "        start = datetime.datetime(2012,1,1)\n",
    "        end = datetime.datetime(2017,6,1)\n",
    "        asset_corr = []\n",
    "        for j in range(len(ids)):\n",
    "            obj2 = {'ratio':[19],'asset':[int(ids[i]) for i in range(len(ids))],'benchmark':int(ids[j]),'start_date':start.isoformat(),'end_date':end.isoformat(),'frequency':None}\n",
    "            obj = json.dumps(obj2)\n",
    "            r = self.session.post(self.url + \"/ratio/invoke\", data = obj, verify = False)\n",
    "            dic = json.loads(r.text)\n",
    "            asset_corr.append([float((dic[str(ids[i])]['19']['value']).replace(\",\",'.')) for i in range(len(ids))])\n",
    "            self.corr_mat = np.array(asset_corr)\n",
    "            self.write_file(self.corr_mat, 'my_corr.txt')\n",
    "        return self.corr_mat\n",
    "    def get_variances(self):\n",
    "        start = datetime.datetime(2012,1,1)\n",
    "        end = datetime.datetime(2017,6,1)\n",
    "        ids = self.ids\n",
    "        var = []\n",
    "        obj2 = {'ratio':[18],'asset':[int(ids[i]) for i in range(len(ids))],'start_date':start.isoformat(),'end_date':end.isoformat(),'frequency':None}\n",
    "        obj = json.dumps(obj2)\n",
    "        r = self.session.post(self.url + \"/ratio/invoke\", data = obj, verify = False)\n",
    "        dic = json.loads(r.text)\n",
    "        var = [float((dic[str(ids[i])]['18']['value']).replace(\",\",'.'))**2 for i in range(len(ids))]\n",
    "        self.var = np.array(var)\n",
    "        self.write_file(self.var, 'my_vars.txt')\n",
    "        return self.var\n",
    "    def get_ass_curr(self):\n",
    "        r = self.get_request(\"asset\")\n",
    "        prices = []\n",
    "        currencys = []\n",
    "        for i in range(len(r)):\n",
    "            a = r[i]['LAST_CLOSE_VALUE']['value']\n",
    "            l = np.array(re.split(\" |,\", a))\n",
    "            price = [l[i]  for i in range(len(l)) if (l[i].isnumeric())]\n",
    "            currency  = r[i]['CURRENCY']['value']\n",
    "            if(len(price) == 2):\n",
    "                price = float(price[0] + '.' + price[1])\n",
    "            else :\n",
    "                price = float(price[0])\n",
    "            prices.append(price)\n",
    "            currencys.append(currency)\n",
    "        self.prx_cur = np.array([np.array(prices), np.array(currencys)]).T\n",
    "        self.write_file(self.prx_cur,'my_prx_curr.txt')\n",
    "        return self.prx_cur\n",
    "    \n",
    "    def get_cov(self):\n",
    "        ids = self.ids\n",
    "        if (self.ids == []):\n",
    "            self.ids = self.get_assetsids()\n",
    "        if (self.corr_mat == []):\n",
    "            self.corr_mat = self.corr_matrix(self, self.ids)\n",
    "        self.cov = np.array([[self.corr_mat[i][j] / np.sqrt(self.var[i] * self.var[j]) for i in range(self.corr_mat.shape[0])]for j in range(self.corr_mat.shape[1]) ])\n",
    "        self.write_file(self.cov, 'my_cov.txt')\n",
    "        return self.cov\n",
    "\n",
    "    def get_portfoliosh(self, ids, Ret_J = False, Sig_J = True):\n",
    "        assert(len(ids) ==20), 'the lentgh of indices should be exactly 20'\n",
    "        w = self.get_weights(ids, Ret_J = Ret_J, Sig_J = Sig_J) \n",
    "        Sigma = []\n",
    "        RT = []\n",
    "        if not(Ret_J):\n",
    "            returns = self.assets65[ids]\n",
    "            RT = np.mean(returns, axis=1).reshape(20,1)\n",
    "        else :\n",
    "            RT = self.assets[ids].reshape(20,1)\n",
    "        if (Sig_J):\n",
    "            Sigma = self.cov[ids][:,ids]\n",
    "        else :\n",
    "            Sigma = self.cov2[ids][:,ids]\n",
    "        \n",
    "        rp =  RT.T.dot(w)\n",
    "        sigmap = np.sqrt(w.T.dot(Sigma.dot(w)))\n",
    "        sharp = rp/sigmap\n",
    "        return np.asscalar(sharp)\n",
    "    def get_asset_quant(self, prx, cur, ammount):\n",
    "        \n",
    "        c = CurrencyRates()\n",
    "        pr = float(prx)\n",
    "       # print(pr, \" cur \", cur, 'amount', ammount)\n",
    "        if (cur == 'EUR'):\n",
    "            self.rest += (float(ammount/ pr) - float(int((ammount/ pr)))) * pr\n",
    "            return float(ammount/ pr)\n",
    "        else:\n",
    "            val = c.convert(cur,'EUR',float(pr))\n",
    "            return float(ammount/val)\n",
    "    def get_assets_quant(self, ids, w, big_amount):\n",
    "        assert(len(ids) == len(w)), 'weights and ids are not the same length'\n",
    "        pc = self.prx_cur\n",
    "        \n",
    "        assets_quant = np.array([self.get_asset_quant(pc[i][0], pc[i][1] ,np.asscalar(big_amount * w[i])) for i in range(len(ids))])\n",
    "        \n",
    "        return assets_quant\n",
    "    def get_assets_quantr(self, ids, w, big_amount):\n",
    "        assqu = self.get_assets_quant(ids, w, big_amount)\n",
    "        assqur =np.zeros(20)\n",
    "        while(self.rest  > 300):\n",
    "            bam = self.rest\n",
    "            self.rest = 0\n",
    "            assqur +=  self.get_assets_quant(ids, w,bam)\n",
    "        return assqu + assqur\n",
    "    def get_bids(self,ids, Ret_J=False, Sig_J= True):\n",
    "        N = len(ids)\n",
    "        Sigma = []\n",
    "        RT = []\n",
    "        if not(Ret_J):\n",
    "            returns = self.assets65[ids]\n",
    "            RT = np.mean(returns, axis=1).reshape(N,1).astype(np.double)\n",
    "        else :\n",
    "            RT = self.assets[ids].reshape(N,1).astype(np.double)\n",
    "        if (Sig_J):\n",
    "            Sigma = self.cov\n",
    "        else :\n",
    "            Sigma = self.cov2\n",
    "        P = matrix(Sigma)\n",
    "        q = matrix(-2 * RT,tc='d')\n",
    "        G = matrix(np.vstack((np.identity(N), -np.identity(N))),tc='d')\n",
    "        h = []\n",
    "        a = 0\n",
    "        h = matrix(np.hstack((0.1 * np.ones(N), np.ones(N) * a)), tc='d')\n",
    "        A = matrix(np.ones(N), (1,N)) \n",
    "        b = matrix([1.0])\n",
    "        sol = solvers.qp(P, q, G, h, A, b)\n",
    "        W = sol['x']\n",
    "        return np.array(W)\n",
    "       \n",
    "    def get_weights(self, ids, Ret_J=False, Sig_J= True):\n",
    "        assert(len(ids) == 20), 'the lentgh of indices should be exactly 20' \n",
    "        Sigma = []\n",
    "        RT = []\n",
    "        if not(Ret_J):\n",
    "            returns = self.assets65[ids]\n",
    "            RT = np.mean(returns, axis=1).reshape(20,1).astype(np.double)\n",
    "        else :\n",
    "            RT = self.assets[ids].reshape(20,1).astype(np.double)\n",
    "        if (Sig_J):\n",
    "            Sigma = self.cov[ids][:,ids]\n",
    "        else :\n",
    "            Sigma = self.cov2[ids][:,ids]\n",
    "            \n",
    "        N = 20\n",
    "        P = matrix(Sigma)\n",
    "        q = matrix(-2 * RT,tc='d')\n",
    "        G = matrix(np.vstack((np.identity(N), -np.identity(N))),tc='d')\n",
    "        h = []\n",
    "        h = matrix(np.hstack((0.1 * np.ones(N), np.ones(N) * -0.01)), tc='d')\n",
    "        A = matrix(np.ones(N), (1,N)) \n",
    "        b = matrix([1.0])\n",
    "        sol = solvers.qp(P, q, G, h, A, b)\n",
    "        W = sol['x']\n",
    "        return np.array(W)\n",
    "    def  dic_ass(self, ids, quants):\n",
    "        val = [{'asset': {'asset': int(ids[i]), 'quantity': int(quants[i])}} for i in range(len(ids))]\n",
    "        return val\n",
    "    def post_portfolio(self, ids, w, amount = 1e7):\n",
    "        self.rest = 0\n",
    "        quants = self.get_assets_quantr(ids,w, amount)\n",
    "        dic_ass = self.dic_ass(ids, quants)\n",
    "        dic = {'currency': {'code': 'EUR'},'label': 'PORTFOLIO_USER5','type': 'front','values': {'2012-01-01': dic_ass}}\n",
    "        obj = json.dumps(dic)\n",
    "        r = self.session.put(self.url + \"/portfolio/\"+str(self.port_id)+\"/dyn_amount_compo\", data = obj, verify = False)\n",
    "        print(\"end posting\")\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/urllib3/connectionpool.py:794: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "#rm.get_request(\"asset?columns=ASSET_DATABASE_ID&columns=LABEL&columns=TYPE&TYPE=PORTFOLIO\")\n",
    "#rm.get_request(\"portfolio/573/dyn_amount_compo\")\n",
    "URL = 'https://dolphin.jump-technology.com:3389/api/v1'\n",
    "user = 'epita_user_5'\n",
    "pwd = 'dolphin23235'\n",
    "rmm = RequestManadger(URL,user, pwd)\n",
    "rmm.get_ass_curr()\n",
    "rm = RequestManadger(URL,user, pwd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 ) Trivial Classificaion by best sharps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Jump Return + Jump Sigma  : 0.20161985138146446\n",
      "Use Jump Return + 65 Sigma  : 80.65770457071\n",
      "Use 65 Return +  Jump Sigma : 0.001624921225077248\n",
      "Use 65 Return + 65 Sigma : 0.6535830034613018\n",
      "Sum of sharpes : 81.51453234677784\n"
     ]
    }
   ],
   "source": [
    "f1 = open(\"my_sharpes.txt\",\"r\")\n",
    "sharpes = np.array(f1.readline().split()).astype(np.float32)\n",
    "f1.close()\n",
    "idx = np.argsort(sharpes)[::-1]\n",
    "ids = idx[:20]\n",
    "\n",
    "sh1 = rm.get_portfoliosh(ids,Ret_J=True, Sig_J=True)\n",
    "sh2 = rm.get_portfoliosh(ids, Ret_J=True, Sig_J=False)\n",
    "sh3 = rm.get_portfoliosh(ids, Ret_J=False, Sig_J=True)\n",
    "sh4 = rm.get_portfoliosh(ids, Ret_J=False, Sig_J=False)\n",
    "print(\"Use Jump Return + Jump Sigma  :\", sh1)\n",
    "print(\"Use Jump Return + 65 Sigma  :\", sh2)\n",
    "print(\"Use 65 Return +  Jump Sigma :\", sh3)\n",
    "print(\"Use 65 Return + 65 Sigma :\", sh4)\n",
    "print(\"Sum of sharpes :\", sh1 + sh2 + sh3 + sh4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Sharpe of sharpe classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Jump Return + Jump Sigma  : 4.412822786111729\n",
      "Use Jump Return + 65 Sigma  : 34.20628368897921\n",
      "Use 65 Return +  Jump Sigma : 0.08297205114393717\n",
      "Use 65 Return + 65 Sigma : 0.34283499788777994\n",
      "Sum of sharpes : 39.04491352412266\n"
     ]
    }
   ],
   "source": [
    "f2 = open(\"my_sharpes65.txt\", \"r\")\n",
    "data2 = f2.readlines() \n",
    "sharpes = np.array([np.array(data2[i].split()).astype(np.float64) for i in range(len(data2))])\n",
    "f2.close()\n",
    "eps = 1e-5\n",
    "#rfs = (sharpes.max() + sharpes.min() ) / 2\n",
    "rfs = sharpes.mean()\n",
    "resharpes = np.array([(sharpes[i].mean() - rfs)/np.var(sharpes[i]) for i in range(sharpes.shape[0])])\n",
    "idx2 = np.argsort(resharpes)[::-1]\n",
    "#print(idx2)\n",
    "ids = idx2[:20]\n",
    "#ids = idd\n",
    "sh1 = rm.get_portfoliosh(ids,Ret_J=True, Sig_J=True)\n",
    "sh2 = rm.get_portfoliosh(ids, Ret_J=True, Sig_J=False)\n",
    "sh3 = rm.get_portfoliosh(ids, Ret_J=False, Sig_J=True)\n",
    "sh4 = rm.get_portfoliosh(ids, Ret_J=False, Sig_J=False)\n",
    "print(\"Use Jump Return + Jump Sigma  :\", sh1)\n",
    "print(\"Use Jump Return + 65 Sigma  :\", sh2)\n",
    "print(\"Use 65 Return +  Jump Sigma :\", sh3)\n",
    "print(\"Use 65 Return + 65 Sigma :\", sh4)\n",
    "print(\"Sum of sharpes :\", sh1 + sh2 + sh3 + sh4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) the most decorelated sharpe classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) with first classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "Use Jump Return + Jump Sigma  : 2.0311756393823486\n",
      "Use Jump Return + 65 Sigma  : 145.82908188671692\n",
      "Use 65 Return +  Jump Sigma : 0.011725850924341634\n",
      "Use 65 Return + 65 Sigma : 0.8413824697439215\n",
      "Sum of sharpes : 148.71336584676754\n"
     ]
    }
   ],
   "source": [
    "#we reduce the assets by dividing by sigma as the correlation matrix would be exactly as covariance matrix because\n",
    "#we want to use the property cov(x+y, z) = cov(x,z) + cov(y, z)\n",
    "import numpy as np\n",
    "#we reduce the assets by dividing by sigma as the correlation matrix would be exactly as covariance matrix because\n",
    "#we want to use the property cov(x+y, z) = cov(x,z) + cov(y, z)\n",
    "idx3 = idx[:50]\n",
    "asrdc = np.array([rm.assets65[i]/np.sqrt(np.var(rm.assets65[i])) for i in range(rm.assets65.shape[0])])\n",
    "\n",
    "D = set(idx3)\n",
    "In = set()\n",
    "k0 = idx3[0]\n",
    "U0 = asrdc[k0]\n",
    "In.add(k0)\n",
    "k1 = list(D - In)[np.argmin([np.abs(np.cov(asrdc[k0], asrdc[j])[0][1]) for j in list(D - In)])]\n",
    "Z0 = asrdc[k1]\n",
    "n = 20\n",
    "for i in range(n - 2):\n",
    "    k0 = k1\n",
    "    In.add(k0)\n",
    "    k1 = list(D - In)[np.argmin([abs(np.cov(U0, asrdc[p])[0][1]) + abs(np.cov(Z0, asrdc[p])[0][1]) for p in list(D - In)])]\n",
    "    Z1 = asrdc[k1]\n",
    "    U1 = U0 + Z0 * np.sign(np.cov(U0, Z1)[0][1]) * np.sign(np.cov(Z0, Z1)[0][1])\n",
    "    In.add(k1)\n",
    "    U0 = U1\n",
    "    Z0 = Z1\n",
    "ids = list(In)\n",
    "print(len(ids))\n",
    "sh1 = rm.get_portfoliosh(ids,Ret_J=True, Sig_J=True)\n",
    "sh2 = rm.get_portfoliosh(ids, Ret_J=True, Sig_J=False)\n",
    "sh3 = rm.get_portfoliosh(ids, Ret_J=False, Sig_J=True)\n",
    "sh4 = rm.get_portfoliosh(ids, Ret_J=False, Sig_J=False)\n",
    "print(\"Use Jump Return + Jump Sigma  :\", sh1)\n",
    "print(\"Use Jump Return + 65 Sigma  :\", sh2)\n",
    "print(\"Use 65 Return +  Jump Sigma :\", sh3)\n",
    "print(\"Use 65 Return + 65 Sigma :\", sh4)\n",
    "print(\"Sum of sharpes :\", sh1 + sh2 + sh3 + sh4)  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm.rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = rm.get_weights(ids,Ret_J=True, Sig_J=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/urllib3/connectionpool.py:794: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end posting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [500]>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm.post_portfolio(ids, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) with second classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "Use Jump Return + Jump Sigma  : 4.364117414687136\n",
      "Use Jump Return + 65 Sigma  : 38.22525282903976\n",
      "Use 65 Return +  Jump Sigma : 0.07822300370440068\n",
      "Use 65 Return + 65 Sigma : 0.34516759793653756\n",
      "Sum of sharpes : 43.012760845367836\n"
     ]
    }
   ],
   "source": [
    "#we reduce the assets by dividing by sigma as the correlation matrix would be exactly as covariance matrix because\n",
    "#we want to use the property cov(x+y, z) = cov(x,z) + cov(y, z)\n",
    "import numpy as np\n",
    "#we reduce the assets by dividing by sigma as the correlation matrix would be exactly as covariance matrix because\n",
    "#we want to use the property cov(x+y, z) = cov(x,z) + cov(y, z)\n",
    "idx4 = idx2[:50]\n",
    "asrdc = np.array([rm.assets65[i]/np.sqrt(np.var(rm.assets65[i])) for i in range(rm.assets65.shape[0])])\n",
    "\n",
    "D = set(idx4)\n",
    "In = set()\n",
    "k0 = idx4[0]\n",
    "U0 = asrdc[k0]\n",
    "In.add(k0)\n",
    "k1 = list(D - In)[np.argmin([np.abs(np.cov(asrdc[k0], asrdc[j])[0][1]) for j in list(D - In)])]\n",
    "Z0 = asrdc[k1]\n",
    "n = 20\n",
    "for i in range(n - 2):\n",
    "    k0 = k1\n",
    "    In.add(k0)\n",
    "    k1 = list(D - In)[np.argmin([abs(np.cov(U0, asrdc[p])[0][1]) + abs(np.cov(Z0, asrdc[p])[0][1]) for p in list(D - In)])]\n",
    "    Z1 = asrdc[k1]\n",
    "    U1 = U0 + Z0 * np.sign(np.cov(U0, Z1)[0][1]) * np.sign(np.cov(Z0, Z1)[0][1])\n",
    "    In.add(k1)\n",
    "    U0 = U1\n",
    "    Z0 = Z1\n",
    "ids = list(In)\n",
    "print(len(ids))\n",
    "sh1 = rm.get_portfoliosh(ids,Ret_J=True, Sig_J=True)\n",
    "sh2 = rm.get_portfoliosh(ids, Ret_J=True, Sig_J=False)\n",
    "sh3 = rm.get_portfoliosh(ids, Ret_J=False, Sig_J=True)\n",
    "sh4 = rm.get_portfoliosh(ids, Ret_J=False, Sig_J=False)\n",
    "print(\"Use Jump Return + Jump Sigma  :\", sh1)\n",
    "print(\"Use Jump Return + 65 Sigma  :\", sh2)\n",
    "print(\"Use 65 Return +  Jump Sigma :\", sh3)\n",
    "print(\"Use 65 Return + 65 Sigma :\", sh4)\n",
    "print(\"Sum of sharpes :\", sh1 + sh2 + sh3 + sh4)  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
